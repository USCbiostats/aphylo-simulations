\documentclass[12pt]{article}

\usepackage{setspace}
  \onehalfspace
  
\usepackage{graphicx}
\usepackage{amsmath, amssymb}

\usepackage[colorlinks=true, allcolors=blue]{hyperref}
  
\usepackage[margin=1in]{geometry}

\newcommand{\isone}[1]{{\boldsymbol{1}\left\{ #1 \right\}}}
\renewcommand{\Pr}[1]{{\mbox{Pr}\left(#1\right) }}
\newcommand{\f}[1]{{f\left(#1\right) }}
\newcommand{\Prcond}[2]{{\mbox{Pr}\left(#1\;\vphantom{#2}\right|\left.\vphantom{#1}#2\right) }}
\newcommand{\fcond}[2]{{f\left(#1\;|\;#2\right) }}
\newcommand{\Expected}[1]{{\mathbb{E}\left\{#1\right\}}}

\title{On the Automatic Annotation of Gene Functions Using Observational Data and Phylogenetic Trees}
\author{Department of Preventive Medicine\\University of Southern California}
\date{This version: \today}

\begin{document}

\maketitle

\section{Introduction}

\section{Definitions}

\subsection{Anotated Phylogenetic Trees}

A phylogenetic tree $\tau\equiv (N,E)$ is a tuple of nodes $N$, and edges $E\equiv \{(n, m) \in N\times N: n\mapsto m\}$ defined by the binary operator $\mapsto$ \emph{parent of}. Furthermore, we define $O(n)\equiv\{m\in N: (n, m) \in E\}$ as the set of offspring of $n$, and $r(m) \equiv\{n \in N: (n, m) \in E\}$ the parent nodes of $m$. For now on we assume that $|r(m)| \leq 1,\forall n\in N$. By definition, all trees have a corresponding undirected shortest path lengths matrix $\Gamma(\tau) \equiv \{\gamma_{nm}\}_{n,m\in N}$, where $\gamma_{nm}$ denotes the undirected shorest path length between genes $n$ and $m$. 

Given $P$ gene functions, let $A \equiv \{a_n \in \{0,1\}^P: n\in N\}$ denote a set of genetic annotations--which we will also refer as states--of the genes $N$. We define an Annotated Phylogenetic Tree as the tuple $D \equiv(\tau, A)$. Furthermore, we say that this structure is a Partially Ordered Annotated Phylogenetic Tree if it's nodes labels form a partial order, this is $E\equiv \{(n, m) \in N\times N: n < m\}$.

While $A$ exists, we only observe an imperfect approximation of it, experimental data $\tilde A = \{\tilde a_l\}_{l\in N}$, which only holds information for some of the leaf nodes. Therefore, for any given leaf node $l$, the elements of $\{\tilde a_{lp}\}_{p=1}^P$ can take the following values:

$$
\tilde a_{lp} = \left\{
\begin{array}{ll}
1 & \mbox{if the function }p\mbox{ is cosidered as active}\\
0 & \mbox{if the function }p\mbox{ is cosidered as non-active}\\
9 & \mbox{if we don't have information }
\end{array}\right.
$$

This way, assuming that we observe the true phylogenetic tree, we denote the tuple $\tilde D\equiv(\tau, \tilde A)$ to be a Experimentally Annotated Phylogenetic Tree. Ultimately, we are interested in predicting functional annotations for the leaf nodes that have not been annotated yet.

\subsection{Likelihood of an Anotated Phylogenetic Tree}

Given $\tilde D$, the probability that the true state is of the $l$-leaf is $a_l = \{a_{lp}\}_{p=1}^P$ is:

\begin{equation}
\label{eq:leaf1}
\Prcond{a_l}{\tilde D, \psi} = \prod_{p = 1}^P\left\{\left[\psi_0^{\tilde a_{lp}}(1-\psi_0)^{1- \tilde a_{lp}}\right]^{1- a_{lp}} \left[\psi_1^{1- \tilde a_{lp}}(1-\psi_1)^{\tilde a_{lp}}\right]^{a_{lp}} \right\}^{\left[1 - \isone{\tilde a_{lp} !=9}\right]}
\end{equation}

Where $\psi\equiv\{\psi_0, \psi_1\}$ is a vector of missclassification probabilities, formally:

$$
\psi_0 = \Prcond{\tilde a_{lp}=1}{a_{lp} = 0},\quad
\psi_1 = \Prcond{\tilde a_{lp}=0}{a_{lp} = 1}
$$

Computationally, observe that the largest parenthesis needs to be calculated only once and then retrieved depending on the values of $(a_{lp},\tilde a_{lp})$. Let $S$ be a square matrix defined as follows

$$
S = \left[\begin{array}{cc}
s_{00} & s_{01} \\
s_{10} & s_{11}
\end{array}\right]
=\left[\begin{array}{cc}
1-\psi_0 & \psi_0 \\
\psi_1 & 1 - \psi_1
\end{array}\right]
$$

Then, \eqref{eq:leaf1} can be rewritten using $S$:

\begin{equation}
\label{eq:leaf2}
\Prcond{a_l}{\tilde D, \psi} = \prod_{p = 1}^P {s_{a_{lp} \tilde a_{lp}}}^{\left[1 - \isone{\tilde a_{lp} !=9}\right]}
\end{equation}

For any internal node $n \in N$, the probability of observing a given state is defined in terms of its offspring $O(n)$, and parameters $(\psi, \mu)$, where $\mu \equiv \{\mu_0,\mu_1\}$ is a vector of probabilities of gain and loss of a function, formally: $
\mu_0 = \Prcond{a_{lp} = 1}{a_{r(l)p} = 0}, \mu_1 = \Prcond{a_{lp} = 0}{a_{r(l)p} = 1}
$. This way, the probability of observing state $a_n = \{a_{np}\}_{p=1}^P$ is


\begin{multline} 
\label{eq:interior1}
\Prcond{a_n}{\tilde D, \psi,\mu} =  \\
\quad\prod_{m \in O_n} \sum_{a_m \in \{0,1\}^P} \Prcond{a_m}{\tilde D, \psi,\mu}
\prod_{p = 1}^P \left\{\left[\mu_0^{a_{mp}}(1-\mu_0)^{1 - a_{mp}}\right]^{1 - a_{np}}
  \left[\mu_1^{1 - a_{mp}}(1-\mu_1)^{a_{mp}}\right]^{a_{np}}\right\} 
\end{multline}

Observe that if $m\in O(n)$ is a leaf node, then $\Prcond{a_m}{\tilde D, \psi,\mu} = \Prcond{a_m}{\tilde D, \psi}$ which was defined in \eqref{eq:leaf2}. Similar to what we did before, Let $M$ be an array of size $2\times 2$ holding the Gain/Loss probabilities, formally: 

$$
M = \left[\begin{array}{cc}
m_{00} & m_{01} \\
m_{10} & m_{11}
\end{array}\right]
= \left[\begin{array}{cc}
1-\mu_0 & \mu_0 \\
\mu_1 & 1 - \mu_1
\end{array}\right]
$$

This way, \eqref{eq:interior1} can be restated as follows

\begin{equation}
\label{eq:interior2}
\Prcond{a_n}{\tilde D, \psi,\mu} = \prod_{m \in O_n} \sum_{a_m \in \{0,1\}^P} \Prcond{a_m}{\tilde D, \psi,\mu}
\prod_p m_{a_{np}a_{mp}}
\end{equation}

Finally, let $\pi\equiv\{\pi_p\}_{p=1}^{P}$ to be the root node state probabilities for each function, then, the likelihood of observing a particular set of annotations conditional on the tree structure and model parameters can be computed using the root node states probabilities:

\begin{equation}
\label{eq:ll}
\Prcond{\tilde A}{\tau,\psi, \mu, \pi} = \sum_{a_0 \in \{0,1\}^P} \Prcond{a_0}{\pi} \Prcond{a_0}{\tilde D,\psi,\mu}
\end{equation}

where $\Prcond{a_0}{\pi} = \prod_{p=1}^P \pi_p^{a_{0p}}\left(1 - \pi_p\right)^{1 - a_{0p}}$.

\section{Estimation}

\subsection{Maximum Likelihood}

Let $\theta = (\psi, \mu, \pi)$ denote the vector of model parameters. Furthermore, $\theta \in \Psi\times \mathcal{M} \times \Pi$, then, the maximun likelihood estimator $\hat \theta$ is

$$
(\hat \psi, \hat \mu, \hat \pi) = \hat\theta = \arg \max_{\theta \in \Theta} \log \Prcond{\tilde A}{\tau, \theta}
$$


\subsection{Markov Chain Monte Carlo with Reflective Boundaries Kernel}

\section{Data Imputation}

The ultimate goal of this model is to be able to predict functional states of leaf nodes. Using both, the information that we have about the annotated tree and the parameter estimates of the model, we can calculate what is the probability of observing either a 0 or a 1 for each given node+function. Formally, the probability of leaf node $l$ having state $a_l = \{a_{lp}\}_{p=1}^P$, conditional on the observed data $(\tau, \tilde A)$ and the model parameter $(\psi, \mu, \pi)$ is:

\begin{equation}
\label{eq:impute1}
\Prcond{a_{np} = 1}{\tau, \tilde A, \psi, \mu, \pi} = \frac{\Prcond{\tilde A}{\tau, \psi, \mu, \pi, a_{np} = 1} \Prcond{a_{np}=1}{\tau, \psi, \mu, \pi}}{
\Prcond{\tilde A}{\tau, \psi, \mu, \pi}
}
\end{equation}

For ease of notation, we will drop the $(\tau, \psi, \mu, \pi)$, as all probabilities throughout this section are conditional on the tree structure and model parameters. Now, we know that

\begin{equation}
\label{eq:prob_evidence}
\Pr{\tilde A} = \Prcond{\tilde A}{a_{np} = 1} \Pr{a_{np} = 1} + \Prcond{\tilde A}{a_{np} = 0} (1 - \Pr{a_{np} = 1})
\end{equation}

Hence, pluging in \eqref{eq:prob_evidence} into \eqref{eq:impute1}, and multiplying both numerator and denominator by $1/\Pr{a_{np} = 1}$, \eqref{eq:impute1} can be rewritten as

\begin{equation}
\tag{\ref*{eq:impute1}'}
\Prcond{a_{np} = 1}{\tilde A} = \frac{\Prcond{\tilde A}{a_{np} = 1}}{
\Prcond{\tilde A}{a_{np} = 1} + \Prcond{\tilde A}{a_{np} = 0} \frac{\left(1 - \Pr{a_{np} = 1}\right)}{\Pr{a_{np} = 1}}
}
\end{equation}

Where $\Prcond{\tilde A}{a_{np} = 1}$ is the likelihood of the data given that we set the ith node to be 1, which we already know how to compute. This way, we are only missing $\Pr{a_{np=1}}$, which we can compute as follows:

\begin{align*}
\Pr{a_{np} = 1} & = \pi_p \Prcond{a_{np} = 1}{a_{0p} = 1} + (1 - \pi_p) \Prcond{a_{np} = 1}{a_{0p} = 0}
\end{align*}


Where, given that $\gamma_{01}$ is the shorest path length between node 0 and node $i$, we have:

$$
\left[\begin{array}{cc}
\Prcond{a_i = 0}{a_0 = 0} & \Prcond{a_i = 1}{a_0 = 0} \\
\Prcond{a_i = 0}{a_0 = 1} & \Prcond{a_i = 1}{a_0 = 1}
\end{array}
\right]
=
\left[\begin{array}{cc}
1 - \hat\mu_0 &  \hat\mu_0 \\
\hat\mu_1 &  1 - \hat\mu_1
\end{array}
\right]^{\gamma_{0i}}
$$


\section{Assesment of Model Predictions}

As our model predictions are probabilities, measuring the quality of of the predictions is not very straight forward. While in an ideal world we would like to count how many of the annotations were correctly predicted, what we can do at best is measure how close the predictions are to the observed data. In this section we propose an statistic to do such.

Let $A_H$ and $\hat A_H$ be the observed and predicted annotations for the set of nodes $H$. Given a matrix of weights $W_H$ which for now we set as $\{\left(\gamma_{hu} + 1\right)^{-1}\}_{h,u\in H}$, which has typical element $\left\{ {w_{hu}} \right\}_{h, u\in H}$, we define the following statistic:

\begin{equation}
\label{eq:delta1}
\delta\left(A_H, \hat A_H\right) = \left\{\left\| a_h - \hat a_h \right\|\right\}_{h \in H}^\mathbf{t}
W_H
\left\{\left\| a_h - \hat a_h \right\|\right\}_{h \in H}
\end{equation}

Where $\|\cdot\|$ is the $\ell^2$-norm. Such can be rewritten as:

\begin{equation}
\label{eq:delta2}
\delta = \sum_{h, u \in H}\left[\sum_{p=1}^P\sum_{r=1}^P (a_{hp} - \hat a_{hp})^2(a_{ur} - \hat a_{ur})^2\right]^{1/2}w_{hu}
\end{equation}

In the best case, we will have $a_h = \hat a_h, \forall h \in H$, which would yield $\delta = 0$. On the other hand, the worse case, the model would yield predictions completely opposed to what we observe, hence $a_h = 1 - \hat a_h, \forall h \in H$, which, following \eqref{eq:delta2}, yields:

\begin{equation*}
\delta\left(A_H, \jmath_{|H|, P} - A_H\right)  = %
\sum_{h, u \in H}\left[\sum_{p=1}^P\sum_{r=1}^P 1\right]^{1/2}w_{hu} = %
\sum_{h, u \in H}Pw_{hu} = P \sum_{h, u \in H}w_{hu} = \underline{\delta}
\end{equation*}

We can also calculate how much better can the model do compared to a random imputation, then, the expected value of $\delta$ equals:

\begin{equation*}
\Expected{\delta} = \sum_{h, u \in H}\Expected{\left[\sum_{p=1}^P\sum_{r=1}^P (a_{hp} - \hat a_{hp})^2(a_{ur} - \hat a_{ur})^2\right]^{1/2}}w_{hu}
\end{equation*}

Furthermore, if we assume that each annotations is randomly distributed $\sim\mbox{Bernoulli}(\alpha)$

\begin{equation}
\Expected{\delta} = \sum_{h, u \in H}w_{hu}\sum_{\hat a_h, \hat a_u \in \{0,1\}^P}\Pr{\hat a_h}\Pr{\hat a_u}\left[\sum_{p=1}^P\sum_{r=1}^P (a_{hp} - \hat a_{hp})^2(a_{ur} - \hat a_{ur})^2\right]^{1/2}
\end{equation}


Where $\Pr{a_h} = \prod_{p=1}^P\alpha^{a_{hp}}(1 - \alpha)^{1 - a_{hp}}$. The relative prediction score 

\begin{equation}
\tilde\delta = \delta \underline{\delta}^{-1},\quad \underline{\bar{\delta}} = \Expected{\delta}\underline{\delta}^{-1}
\end{equation}

We can also compute the variance of such statistic. Since we already have $\Expected{\delta}$, we just need to calculate $\Expected{\delta^2}$. It can be shown that it has the following form:

\begin{multline}
\Expected{\delta^2} = \sum_{h, u, h', u' \in H} w_{nu}w_{n'u'} %
\sum_{\hat a_h, \hat a_u, \hat a_{h'}, \hat a_{u'} \in \{0,1\}^P} % 
\Pr{\hat a_h}\Pr{\hat a_u}\Pr{\hat a_{h'}}\Pr{\hat a_{u'}} \left[\vphantom{\sum_{p}}\right. \\
\left. \sum_{p,r,p',r'} %
(a_{hp} - \hat a_{hp})^2(a_{ur} - \hat a_{ur})^2(a_{h'p'} - \hat a_{h'p'})^2(a_{u'r'} - \hat a_{u'r'})^2\right]^{1/2}
\end{multline}

\section{Monte Carlo Simulations}

\subsection{Data Generating Process}

For each phylogenetic tree $\tau$ of $\mathcal{T}$--the PANTHER dataset which roughly has 13,000 trees--we did the following:

\begin{enumerate}
	\item Draw $(\psi, \mu, \pi)$ each from a $B(1, 20)$
	\item Simulate $A | (\tau, \psi, \mu, \pi)$
	\item Randomly select a set $M\subset N$ of size $q$ such that the probability of selecting a leaf $l$ with $a_{lp} = 1$ equals 0.8, and the probability of selecting a leaf with $l'$ with $a_{lp} = 0$ equals 0.2.
	\item Set $a_l = 9 \forall l \in M$
	\item next $\tau$
\end{enumerate}

\subsection{Bias}


\subsection{Convergence of the MCMC}

\section{Discussion}

\subsection{Extensions to the model}

Including branch lengths (time)

\appendix

\section{Data}

The model uses two different datasets: (1) experimental data, which holds functions indicators, and (2) phylogenetic tree data, which contains the parent/offspring relations.

Given how the algorithm for computing the likelihood has been programmed, it is necessary that the experimental dataset must have as many rows as nodes (parents and offspring) there are. To fulfill such requirement, the package 'phylogenetic', throught the function 'prepare\_data', ''completes'' the experimental dataset as follows:

1.  List all nodes in the tree that are not in the experimental dataset.

2.  Once identified, if any, add those nodes to the experimental dataset. The
    function indicator columns will have value '9' (unknown). Furthermore, the
    added nodes are tagged so that the user can identify them later.
    
3.  The new experimental dataset is sorted increasingly according to the node
    id number. The idea is that the root, node 0, should appear in the
    first row.
    
Once the experimental data has been processed, 
    
4.  We identify

\section{ Maximum a Posteriori (MAP) Estimation}

Using bayes we have

$$
\fcond{\theta}{D} = \frac{\fcond{X}{\theta}\f{\theta}}{f{X}}
$$

Then, assumming iid, to estimate $\hat \theta$ we can solve the following problem

\begin{align*}
\label{eq:maptheta}
\hat \theta & = \arg\max_{\theta \in \Theta} \frac{\fcond{X}{\theta}\f{\theta}}{\f{X}} \\
 & \mbox{Since the denominator is constant, this is equivalent to} \\
 & = \arg\max_{\theta \in \Theta} \fcond{X}{\theta}\f{\theta} \tag{MAP estimate} 
\end{align*}


Observe that under a uniform prior, this is equivalent to the MLE estimate. Now, the variance (what about the covariance) estimator is as follows

\begin{equation}
\label{eq:mapvar}
\mbox{Var}\left(\hat\theta\right) = \int_{\theta \in \Theta} \left(\hat\theta - \theta\right)^2
\frac{\fcond{X}{\theta}\f{\theta}}{\f{X}} d\theta \tag{MAP variance}
\end{equation}

Where the denominator, probability of evidence, can be computed as

$$
\label{eq:d}
\f{X} = \int_{\theta \in \Theta} \fcond{X}{\theta}\f{\theta}d\theta 
$$

Given $\hat \theta$, the variance can be computed using numerical integration.

\end{document}